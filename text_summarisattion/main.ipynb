{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# text = \"\"\"\n",
    "# Artificial Intelligence (AI) has been a rapidly advancing field over the past few decades. Initially, AI was primarily used in academic research and niche applications. However, recent breakthroughs in machine learning and neural networks have allowed AI to permeate various industries, from healthcare to finance to entertainment. Companies are increasingly leveraging AI to automate processes, gain insights from large data sets, and enhance customer experiences.\n",
    "\n",
    "# One of the most notable advancements in AI is the development of natural language processing (NLP) techniques. NLP enables machines to understand and respond to human language, leading to the creation of chatbots, virtual assistants, and more. This has revolutionized the way businesses interact with their customers, providing instant support and personalized experiences.\n",
    "\n",
    "# Despite these advancements, there are still challenges to overcome. Issues such as data privacy, algorithmic bias, and the need for vast amounts of data to train models remain significant. As AI continues to evolve, addressing these challenges will be crucial to ensure that its benefits are realized equitably and responsibly.\n",
    "\n",
    "# Overall, the future of AI looks promising. Continued research and development in this field have the potential to unlock new possibilities and transform the way we live and work. As we move forward, it will be essential to balance innovation with ethical considerations to create a future where AI benefits everyone.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "text = \"\"\"One day a rabbit was boasting about how fast he could run. He was laughing at the turtle for being so slow. Much to the rabbitâ€™s surprise, the turtle challenged him to a race. The rabbit thought this was a good joke and accepted the challenge. The fox was to be the umpire of the race. As the race began, the rabbit raced way ahead of the turtle, just like everyone thought.\n",
    "The rabbit got to the halfway point and could not see the turtle anywhere. He was hot and tired and decided to stop and take a short nap. Even if the turtle passed him, he would be able to race to the finish line ahead of him. All this time the turtle kept walking step by step by step. He never quit no matter how hot or tired he got. He just kept going.\n",
    "However, the rabbit slept longer than he had thought and woke up. He could not see the turtle anywhere! He went at full speed to the finish line but found the turtle there waiting for him.\"\"\"\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    processed_sentences = [\" \".join([word for word in sentence.lower().split() if word not in stop_words])\n",
    "                           for sentence in sentences]\n",
    "    return sentences, processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive Summary: The rabbit got to the halfway point and could not see the turtle anywhere. He could not see the turtle anywhere!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from transformers import pipeline\n",
    "\n",
    "# Extractive Summarization\n",
    "def extractive_summary(text, num_sentences=2):\n",
    "    sentences, processed_sentences = preprocess_text(text)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(processed_sentences)\n",
    "    similarity_matrix = np.dot(X, X.T).toarray()\n",
    "\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    # Ensure num_sentences does not exceed the number of sentences in the input text\n",
    "    num_sentences = min(num_sentences, len(ranked_sentences))\n",
    "    \n",
    "    summary = \" \".join([ranked_sentences[i][1] for i in range(num_sentences)])\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "extractive = extractive_summary(text)\n",
    "print(\"Extractive Summary:\", extractive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstractive Summary: a rabbit was laughing at the turtle for being so slow he could run . the rabbit raced way ahead of the turtle, just like everyone thought . if the turtle passed him, he would be able to race to the finish line .\n"
     ]
    }
   ],
   "source": [
    "# Abstractive Summarization\n",
    "def abstractive_summary(text, max_length=200, min_length=50):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Example usage\n",
    "abstractive = abstractive_summary(text)\n",
    "\n",
    "print(\"Abstractive Summary:\", abstractive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
